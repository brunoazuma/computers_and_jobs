---
title: "RAIS"
output: html_notebook
csl: associacao-brasileira-de-normas-tecnicas-ipea.csl
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook for the exploratory analysis and preparation of data from the Relação Anual de Informações Sociais (RAIS) of the brazilian federal Ministry of Labor and Employment, as made available by [Base dos Dados](https://basedosdados.org/).

```{r}
setwd("D:/OneDrive/R Workspace/computers_and_jobs")
# install.packages(\"dotenv\")
library("dotenv")
# install.packages('arrow')
library(arrow, warn.conflicts = FALSE)
# install.packages("basedosdados")
library("basedosdados")
# install.packages("tidyverse")
library("tidyverse")
```
First, I need to setup the GCP project data for using the `basedosdados` package to get the data.

```{r}
# Defina o seu projeto no Google Cloud
project_id <- Sys.getenv("GCP_PROJECT_ID")
basedosdados::set_billing_id(project_id)
```
Second, just a peek at one line of tha RAIS table to make sure everythin is ok.

```{r}
# Para carregar o dado direto no R
peek <- basedosdados::read_sql("SELECT *
FROM `basedosdados.br_me_rais.microdados_vinculos`
LIMIT 1")
```


```{r}
peek %>% dplyr::glimpse()
```

Now, I setup a function with the query with all the data I need from the table. At this point, I'm not doing any aggregation yet. Just downloading the table and saving locally as a parquet file.

```{r}
download_rais <- function(uf, year) {
  sql <- "
  SELECT
    tb_rais.ano,
    tb_rais.sigla_uf,
    tb_rais.cnae_2,
    tb_rais.cbo_2002,
    tb_rais.grau_instrucao_apos_2005,
    tb_rais.sexo,
    tb_rais.raca_cor,
    AVG(tb_rais.valor_remuneracao_media_sm) AS valor_remuneracao_media_sm,
    AVG(tb_rais.valor_remuneracao_media) AS valor_remuneracao_media
  FROM
    `basedosdados.br_me_rais.microdados_vinculos` AS tb_rais
  WHERE
    ano = ${year}
    AND
    sigla_uf = '${uf}'
  GROUP BY
    tb_rais.ano,
    tb_rais.sigla_uf,
    tb_rais.cnae_2,
    tb_rais.cbo_2002,
    tb_rais.grau_instrucao_apos_2005,
    tb_rais.sexo,
    tb_rais.raca_cor;
  "
  interp_sql <- str_interp(sql)
  # print(interp_sql)
  
  data <- basedosdados::read_sql(interp_sql)
  
  data_dir <- "./data/RAIS/reduced/"
  file_path <- str_interp("${data_dir}RAIS_${year}_${uf}.parquet")
  write_parquet(data, file_path)
}
```

Now, I prepare the years and Federative units lists for download.

```{r eval=FALSE, include=FALSE}
years <- c(2008, 2009, 2010)
ufs <- basedosdados::read_sql("SELECT sigla FROM `basedosdados.br_bd_diretorios_brasil.uf`")
```

And download the data for all of the Federative Units, except SP.

```{r eval=FALSE, include=FALSE}
for (year in years) {
  for (uf in ufs$sigla) {
    if (uf != 'SP') {
      download_rais(uf, year)
    }
  }
}
```
Lastly, I download the SP data.

```{r eval=FALSE, include=FALSE}
years <- c(2008, 2009, 2010)
for (year in years) {
    download_rais('SP', year)
}
```

Now I aggregate the data.

```{r}
print('Starting aggregation')
print(Sys.time())

data_dir <- "./data/RAIS/reduced/"
rais_sum <- NULL

for (year in years) {
  print(str_interp("Starting aggregation for year ${year}..."))
  for (uf in ufs$sigla) {
  
    file_path <- str_interp("${data_dir}RAIS_${year}_${uf}.parquet")
    print(str_interp("Reading ${file_path}..."))
    rais <- read_parquet(file_path)
    
    if (is.null(rais_sum)) {
      rais_sum <- rais
    } else {
      rais_sum <- bind_rows(rais_sum, rais)
    }
    print(str_interp("${file_path} has been read."))
    print(Sys.time())
  
  }
  print(str_interp("Year ${year} has been read."))
  print(Sys.time())
}
print('Ending aggregation')
print(Sys.time())

rais_sum
```

Finally, I save the final dataset with all years and Federative Units.

```{r}
write_parquet(rais_sum, str_interp("${data_dir}/RAIS.parquet"))
```

